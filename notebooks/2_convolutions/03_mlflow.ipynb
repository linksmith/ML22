{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 11:31:54.116158: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 11:31:55.453227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.data import make_dataset\n",
    "from pathlib import Path\n",
    "from loguru import logger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with our good'ol MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\"../../data/raw/\")\n",
    "batch_size = 64\n",
    "train_dataloader, test_dataloader = make_dataset.get_MNIST(datadir, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir.resolve().exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938, 157)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain an item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_dataloader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image follows the channels-first convention: (channel, width, height). The label is an integer.\n",
    "\n",
    "Let's re-use the model we had:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 11:50:16.281 | INFO     | __main__:__init__:26 - Aggregating activationmap with size torch.Size([2, 2])\n",
      "2023-05-16 11:50:16.300 | INFO     | __main__:__init__:70 - Aggregating activationmap with size torch.Size([2, 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, filters, units1, units2, input_size=(32, 1, 28, 28)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        activation_map_size = self._conv_test(input_size)\n",
    "        logger.info(f\"Aggregating activationmap with size {activation_map_size}\")\n",
    "        self.agg = nn.AvgPool2d(activation_map_size)\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, 10)\n",
    "        )\n",
    "\n",
    "    def _conv_test(self, input_size = (32, 1, 28, 28)):\n",
    "        x = torch.ones(input_size)\n",
    "        x = self.convolutions(x)\n",
    "        return x.shape[-2:]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutions(x)\n",
    "        x = self.agg(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "# Define model\n",
    "class CNN_J(nn.Module):\n",
    "    def __init__(self, filters, units1, units2, input_size=(32, 1, 28, 28)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(1, filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=0),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=0),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),            \n",
    "        )\n",
    "\n",
    "        activation_map_size = self._conv_test(input_size)\n",
    "        logger.info(f\"Aggregating activationmap with size {activation_map_size}\")\n",
    "        self.agg = nn.AvgPool2d(activation_map_size)\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(filters, units1),            \n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Linear(units1, units2)            ,\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Linear(units2, 10)\n",
    "        )\n",
    "\n",
    "    def _conv_test(self, input_size = (32, 1, 28, 28)):\n",
    "        x = torch.ones(input_size)\n",
    "        x = self.convolutions(x)\n",
    "        return x.shape[-2:]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutions(x)\n",
    "        x = self.agg(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "model = CNN(filters=32, units1=128, units2=64).to(device)\n",
    "model_J = CNN_J(filters=32, units1=128, units2=64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "         LeakyReLU-2           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
      "            Conv2d-4           [-1, 32, 12, 12]           9,248\n",
      "         LeakyReLU-5           [-1, 32, 12, 12]               0\n",
      "         MaxPool2d-6             [-1, 32, 6, 6]               0\n",
      "            Conv2d-7             [-1, 32, 4, 4]           9,248\n",
      "         LeakyReLU-8             [-1, 32, 4, 4]               0\n",
      "         MaxPool2d-9             [-1, 32, 2, 2]               0\n",
      "        AvgPool2d-10             [-1, 32, 1, 1]               0\n",
      "          Flatten-11                   [-1, 32]               0\n",
      "           Linear-12                  [-1, 128]           4,224\n",
      "        LeakyReLU-13                  [-1, 128]               0\n",
      "           Linear-14                   [-1, 64]           8,256\n",
      "        LeakyReLU-15                   [-1, 64]               0\n",
      "           Linear-16                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 31,946\n",
      "Trainable params: 31,946\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.52\n",
      "Params size (MB): 0.12\n",
      "Estimated Total Size (MB): 0.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_J, input_size=(1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And set up the optimizer, loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from src.models import metrics\n",
    "# optimizer = optim.Adam\n",
    "optimizer = optim.AdamW\n",
    "# optimizer = optim.SGD\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1094)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(x)\n",
    "accuracy(y, yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow\n",
    "MLflow is an open-source platform designed to manage the entire Machine Learning (ML) lifecycle, including experimentation, reproducibility, deployment, and governance. It provides a set of APIs and tools to streamline ML workflows, making it easier to track experiments, package code, manage model versions, and deploy models.\n",
    "\n",
    "Reasons to use MLflow over TensorBoard, gin-config, or Ray:\n",
    "\n",
    "- End-to-end ML lifecycle management: While TensorBoard focuses on visualizing model training metrics and gin-config on hyperparameter configuration, MLflow covers a broader range of tasks, such as experiment tracking, model packaging, and deployment.\n",
    "\n",
    "- Framework agnostic: MLflow is not tied to a specific ML framework, making it suitable for projects using different libraries or even multiple libraries.\n",
    "\n",
    "- Model Registry: MLflow provides a centralized model registry, allowing you to version, track, and manage your models, which is not available in TensorBoard or gin-config.\n",
    "\n",
    "- Deployment support: MLflow facilitates model deployment to various platforms, such as local, cloud, or Kubernetes environments, whereas TensorBoard and gin-config are not built for deployment tasks.\n",
    "\n",
    "- Integration with other tools: MLflow integrates with popular tools and platforms like Databricks, AWS, and Azure, making it easy to incorporate into existing workflows.\n",
    "\n",
    "However, the choice between MLflow and other tools like TensorBoard, gin-config, or Ray depends on your specific use case and the scope of the ML workflow you want to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/jeremycs/Development/machinelearning/ML22/notebooks/2_convolutions/mlruns/1', creation_time=1683986227006, experiment_id='1', last_update_time=1683986227006, lifecycle_stage='active', name='mnist_convolutions', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"mnist_convolutions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we set the MLflow tracking URI to a local SQLite database file. This is done to configure the storage location for MLflow's experiment tracking data, such as metrics, parameters, and artifacts. By specifying a SQLite database, we enable a lightweight and easy-to-use storage solution for tracking the experiments and their associated information.\n",
    "\n",
    "The line mlflow.set_experiment(\"mnist_convolutions\") sets the active MLflow experiment to \"mnist_convolutions\". This is useful for organizing and grouping your runs, as it allows you to associate the upcoming ML training runs with a specific experiment name, making it easier to search, compare, and analyze the results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import functions and classes from the hyperopt library to perform hyperparameter optimization. This library helps us find the best hyperparameter values for our machine learning model by searching through a defined search space and using optimization algorithms like Tree-structured Parzen Estimator (TPE). The goal is to improve our model's performance by tuning its hyperparameters.\n",
    "\n",
    "Advantages of TPE:\n",
    "\n",
    "- Model-based approach: TPE is a Bayesian optimization method that models the objective function as a probability distribution. It learns from previous evaluations to decide which points in the search space to explore next, making it more efficient in finding optimal hyperparameters.\n",
    "\n",
    "- Exploration-exploitation trade-off: TPE balances the trade-off between exploration (searching in new regions of the search space) and exploitation (refining around the current best points). This can lead to better results in problems with complex search spaces.\n",
    "\n",
    "- Continuous hyperparameter optimization: TPE can handle continuous hyperparameters more naturally, as it builds a probability model to estimate the performance for any given point in the search space.\n",
    "\n",
    "Lets set up an objective function and start logging some usefull things we might want to track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from src.models import metrics\n",
    "from src.models import train_model\n",
    "from datetime import datetime\n",
    "from src.data import make_dataset\n",
    "modeldir = Path(\"/Users/jeremycs/Development/machinelearning/ML22/src/models\")\n",
    "datadir = Path(\"../../data/raw/\")\n",
    "\n",
    "# Define the objective function for hyperparameter optimization\n",
    "def objective(params):\n",
    "    # Start a new MLflow run for tracking the experiment\n",
    "    with mlflow.start_run():\n",
    "        # Set MLflow tags to record metadata about the model and developer\n",
    "        mlflow.set_tag(\"model\", \"convnet\")\n",
    "        mlflow.set_tag(\"dev\", \"linksmith\")\n",
    "        # Log hyperparameters to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"datadir\", f\"{datadir.resolve()}\")\n",
    "        mlflow.log_param(\"batchsize\", f\"{batch_size}\")\n",
    "\n",
    "        # Initialize the optimizer, loss function, and accuracy metric      \n",
    "        # optimizer = optim.Adam\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        accuracy = metrics.Accuracy()\n",
    "        \n",
    "        selected_search_space = {\n",
    "            'filters': params['filters'],\n",
    "            'units1': params['units1'],\n",
    "            'units2': params['units2']\n",
    "        }\n",
    "        model_j = CNN_J(**selected_search_space)\n",
    "        \n",
    "        # Select the optimizer based on the choice in params\n",
    "        if params['optimizer'] == 'SGD':\n",
    "            optimizer = torch.optim.SGD\n",
    "        elif params['optimizer'] == 'Adam':\n",
    "            optimizer = torch.optim.Adam\n",
    "        elif params['optimizer'] == 'AdamW':\n",
    "            optimizer = torch.optim.AdamW\n",
    "            \n",
    "        train_dataloader, test_dataloader = make_dataset.get_MNIST(datadir, batch_size=params['batch_size']) \n",
    " \n",
    "        # Instantiate the CNN model with the given hyperparameters\n",
    "        # Train the model using a custom train loop\n",
    "        model_j, test_loss = train_model.trainloop(\n",
    "            epochs=3,\n",
    "            model=model_j,\n",
    "            optimizer=optimizer,\n",
    "            learning_rate=params['learning_rate'],\n",
    "            loss_fn=loss_fn,\n",
    "            metrics=[accuracy],\n",
    "            train_dataloader=train_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            log_dir=\"modellog\",\n",
    "            # set the tunewriter to mlflow.\n",
    "            tunewriter=[\"mlflow\"],\n",
    "            train_steps=100, #len(train_dataloader),\n",
    "            eval_steps=100, #len(test_dataloader),\n",
    "        )\n",
    "\n",
    "        # Save the trained model with a timestamp   \n",
    "        tag = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "        modelpath = modeldir / (tag + \"model.pt\")\n",
    "        torch.save(model_j, modelpath)\n",
    "\n",
    "        # Log the saved model as an artifact in MLflow\n",
    "        mlflow.log_artifact(local_path=modelpath, artifact_path=\"pytorch_models\")\n",
    "        return {'loss' : test_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space_1 = {\n",
    "#     'filters' : scope.int(hp.quniform('filters', 16, 128, 8)),\n",
    "#     'units1' : scope.int(hp.quniform('units1', 32, 128, 8)),\n",
    "#     'units2' : scope.int(hp.quniform('units2', 32, 128, 8)),\n",
    "# }\n",
    "\n",
    "# search_space_2 = {\n",
    "#     'filters' : scope.int(hp.quniform('filters', 104, 124, 2)),\n",
    "#     'units1' : scope.int(hp.quniform('units1', 58, 78, 2)),\n",
    "#     'units2' : scope.int(hp.quniform('units2', 52, 92, 4)),\n",
    "# }\n",
    "\n",
    "search_space = {\n",
    "    'filters' : scope.int(hp.quniform('filters', 118, 122, 2)),\n",
    "    'units1' : scope.int(hp.quniform('units1', 64, 68, 2)),\n",
    "    'units2' : scope.int(hp.quniform('units2', 86, 90, 2)),\n",
    "    'learning_rate' : scope.int(hp.quniform('learning_rate', 0.0005, 0.0015, 0.0005)),\n",
    "    'optimizer': hp.choice('optimizer', ['SGD', 'Adam', 'AdamW']),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 32, 96, 32)) \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a search space for hyperparameter optimization using Hyperopt. The search space specifies the range and distribution of hyperparameters to explore during the optimization process. This is crucial for finding the optimal set of hyperparameters that yield the best performance for the machine learning model. The search space defined here includes the number of filters in the convolutional layers, and the number of units in two fully connected layers, allowing Hyperopt to find the best combination within the given ranges.\n",
    "\n",
    "\n",
    "Now, finally, let us perform the hyperparameter search using the fmin function from hyperopt. The function takes the following arguments:\n",
    "\n",
    "- `fn=objective`: The objective function to minimize, which is defined earlier to train the model and return the test loss.\n",
    "- `space=search_space`: The search space defined earlier, containing the range of hyperparameters to explore.\n",
    "- `algo=tpe.suggest`: The optimization algorithm to use, in this case, the Tree-structured Parzen Estimator (TPE) method.\n",
    "- `max_evals=10`: The maximum number of function evaluations, i.e., the maximum number of hyperparameter combinations to try.\n",
    "- `trials=Trials()`: A Trials object to store the results of each evaluation.\n",
    "\n",
    "The fmin function searches for the best hyperparameters within the given search space using the TPE algorithm, aiming to minimize the objective function (test loss). Once the optimization process is completed, the best hyperparameters found are stored in the best_result variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 12:00:57.407 | INFO     | __main__:__init__:70 - Aggregating activationmap with size torch.Size([2, 2])\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/3 [00:00<?, ?it/s]\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|\u001b[38;2;30;71;6m1         \u001b[0m| 1/100 [00:00<00:14,  6.98it/s]\u001b[A\n",
      "  3%|\u001b[38;2;30;71;6m3         \u001b[0m| 3/100 [00:00<00:08, 12.09it/s]\u001b[A\n",
      "  5%|\u001b[38;2;30;71;6m5         \u001b[0m| 5/100 [00:00<00:06, 14.97it/s]\u001b[A\n",
      "  7%|\u001b[38;2;30;71;6m7         \u001b[0m| 7/100 [00:00<00:05, 16.40it/s]\u001b[A\n",
      " 10%|\u001b[38;2;30;71;6m#         \u001b[0m| 10/100 [00:00<00:04, 18.18it/s]\u001b[A\n",
      " 12%|\u001b[38;2;30;71;6m#2        \u001b[0m| 12/100 [00:00<00:07, 11.75it/s]\u001b[A\n",
      " 14%|\u001b[38;2;30;71;6m#4        \u001b[0m| 14/100 [00:01<00:08, 10.58it/s]\u001b[A\n",
      " 16%|\u001b[38;2;30;71;6m#6        \u001b[0m| 16/100 [00:01<00:07, 10.63it/s]\u001b[A\n",
      " 18%|\u001b[38;2;30;71;6m#8        \u001b[0m| 18/100 [00:01<00:07, 10.91it/s]\u001b[A\n",
      " 20%|\u001b[38;2;30;71;6m##        \u001b[0m| 20/100 [00:01<00:07, 11.16it/s]\u001b[A\n",
      " 22%|\u001b[38;2;30;71;6m##2       \u001b[0m| 22/100 [00:01<00:06, 11.67it/s]\u001b[A\n",
      " 24%|\u001b[38;2;30;71;6m##4       \u001b[0m| 24/100 [00:01<00:06, 12.64it/s]\u001b[A\n",
      " 26%|\u001b[38;2;30;71;6m##6       \u001b[0m| 26/100 [00:02<00:05, 12.61it/s]\u001b[A\n",
      " 28%|\u001b[38;2;30;71;6m##8       \u001b[0m| 28/100 [00:02<00:05, 12.16it/s]\u001b[A\n",
      " 30%|\u001b[38;2;30;71;6m###       \u001b[0m| 30/100 [00:02<00:06, 10.58it/s]\u001b[A\n",
      " 32%|\u001b[38;2;30;71;6m###2      \u001b[0m| 32/100 [00:02<00:06, 11.00it/s]\u001b[A\n",
      " 34%|\u001b[38;2;30;71;6m###4      \u001b[0m| 34/100 [00:02<00:05, 11.16it/s]\u001b[A\n",
      " 36%|\u001b[38;2;30;71;6m###6      \u001b[0m| 36/100 [00:03<00:09,  7.00it/s]\u001b[A\n",
      " 38%|\u001b[38;2;30;71;6m###8      \u001b[0m| 38/100 [00:03<00:08,  7.75it/s]\u001b[A\n",
      " 40%|\u001b[38;2;30;71;6m####      \u001b[0m| 40/100 [00:03<00:06,  9.02it/s]\u001b[A\n",
      " 42%|\u001b[38;2;30;71;6m####2     \u001b[0m| 42/100 [00:04<00:06,  8.65it/s]\u001b[A\n",
      " 44%|\u001b[38;2;30;71;6m####4     \u001b[0m| 44/100 [00:04<00:05,  9.82it/s]\u001b[A\n",
      " 46%|\u001b[38;2;30;71;6m####6     \u001b[0m| 46/100 [00:04<00:05, 10.12it/s]\u001b[A\n",
      " 48%|\u001b[38;2;30;71;6m####8     \u001b[0m| 48/100 [00:04<00:05,  9.19it/s]\u001b[A\n",
      " 50%|\u001b[38;2;30;71;6m#####     \u001b[0m| 50/100 [00:04<00:05,  9.26it/s]\u001b[A\n",
      " 52%|\u001b[38;2;30;71;6m#####2    \u001b[0m| 52/100 [00:04<00:05,  9.55it/s]\u001b[A\n",
      " 55%|\u001b[38;2;30;71;6m#####5    \u001b[0m| 55/100 [00:05<00:03, 12.21it/s]\u001b[A\n",
      " 58%|\u001b[38;2;30;71;6m#####8    \u001b[0m| 58/100 [00:05<00:02, 14.57it/s]\u001b[A\n",
      " 61%|\u001b[38;2;30;71;6m######1   \u001b[0m| 61/100 [00:05<00:02, 16.57it/s]\u001b[A\n",
      " 64%|\u001b[38;2;30;71;6m######4   \u001b[0m| 64/100 [00:05<00:02, 18.00it/s]\u001b[A\n",
      " 66%|\u001b[38;2;30;71;6m######6   \u001b[0m| 66/100 [00:05<00:01, 17.17it/s]\u001b[A\n",
      " 69%|\u001b[38;2;30;71;6m######9   \u001b[0m| 69/100 [00:05<00:01, 18.39it/s]\u001b[A\n",
      " 72%|\u001b[38;2;30;71;6m#######2  \u001b[0m| 72/100 [00:05<00:01, 19.43it/s]\u001b[A\n",
      " 75%|\u001b[38;2;30;71;6m#######5  \u001b[0m| 75/100 [00:06<00:01, 20.33it/s]\u001b[A\n",
      " 78%|\u001b[38;2;30;71;6m#######8  \u001b[0m| 78/100 [00:06<00:01, 20.70it/s]\u001b[A\n",
      " 81%|\u001b[38;2;30;71;6m########1 \u001b[0m| 81/100 [00:06<00:00, 20.82it/s]\u001b[A\n",
      " 84%|\u001b[38;2;30;71;6m########4 \u001b[0m| 84/100 [00:06<00:00, 20.12it/s]\u001b[A\n",
      " 87%|\u001b[38;2;30;71;6m########7 \u001b[0m| 87/100 [00:06<00:00, 19.83it/s]\u001b[A\n",
      " 90%|\u001b[38;2;30;71;6m######### \u001b[0m| 90/100 [00:06<00:00, 20.63it/s]\u001b[A\n",
      " 93%|\u001b[38;2;30;71;6m#########3\u001b[0m| 93/100 [00:06<00:00, 21.19it/s]\u001b[A\n",
      " 96%|\u001b[38;2;30;71;6m#########6\u001b[0m| 96/100 [00:07<00:00, 21.63it/s]\u001b[A\n",
      " 99%|\u001b[38;2;30;71;6m#########9\u001b[0m| 99/100 [00:07<00:00, 21.84it/s]\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m##########\u001b[0m| 100/100 [00:07<00:00, 13.75it/s]\n",
      "2023-05-16 12:01:06.815 | INFO     | src.models.train_model:trainloop:180 - Epoch 0 train 2.3051 test 2.3059 metric ['0.1056']\n",
      " 33%|\u001b[38;2;30;71;6m###3      \u001b[0m| 1/3 [00:09<00:18,  9.31s/it]\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|\u001b[38;2;30;71;6m2         \u001b[0m| 2/100 [00:00<00:05, 17.32it/s]\u001b[A\n",
      "  4%|\u001b[38;2;30;71;6m4         \u001b[0m| 4/100 [00:00<00:05, 18.35it/s]\u001b[A\n",
      "  6%|\u001b[38;2;30;71;6m6         \u001b[0m| 6/100 [00:00<00:05, 18.60it/s]\u001b[A\n",
      "  8%|\u001b[38;2;30;71;6m8         \u001b[0m| 8/100 [00:00<00:05, 17.88it/s]\u001b[A\n",
      " 10%|\u001b[38;2;30;71;6m#         \u001b[0m| 10/100 [00:00<00:05, 16.61it/s]\u001b[A\n",
      " 12%|\u001b[38;2;30;71;6m#2        \u001b[0m| 12/100 [00:00<00:05, 17.50it/s]\u001b[A\n",
      " 14%|\u001b[38;2;30;71;6m#4        \u001b[0m| 14/100 [00:00<00:04, 17.53it/s]\u001b[A\n",
      " 16%|\u001b[38;2;30;71;6m#6        \u001b[0m| 16/100 [00:00<00:04, 17.21it/s]\u001b[A\n",
      " 18%|\u001b[38;2;30;71;6m#8        \u001b[0m| 18/100 [00:01<00:04, 17.94it/s]\u001b[A\n",
      " 20%|\u001b[38;2;30;71;6m##        \u001b[0m| 20/100 [00:01<00:04, 18.46it/s]\u001b[A\n",
      " 22%|\u001b[38;2;30;71;6m##2       \u001b[0m| 22/100 [00:01<00:04, 15.90it/s]\u001b[A\n",
      " 24%|\u001b[38;2;30;71;6m##4       \u001b[0m| 24/100 [00:01<00:05, 14.42it/s]\u001b[A\n",
      " 26%|\u001b[38;2;30;71;6m##6       \u001b[0m| 26/100 [00:01<00:05, 13.38it/s]\u001b[A\n",
      " 28%|\u001b[38;2;30;71;6m##8       \u001b[0m| 28/100 [00:01<00:06, 11.56it/s]\u001b[A\n",
      " 30%|\u001b[38;2;30;71;6m###       \u001b[0m| 30/100 [00:02<00:06, 10.22it/s]\u001b[A\n",
      " 32%|\u001b[38;2;30;71;6m###2      \u001b[0m| 32/100 [00:02<00:06,  9.94it/s]\u001b[A\n",
      " 34%|\u001b[38;2;30;71;6m###4      \u001b[0m| 34/100 [00:02<00:06, 10.65it/s]\u001b[A\n",
      " 36%|\u001b[38;2;30;71;6m###6      \u001b[0m| 36/100 [00:02<00:07,  8.50it/s]\u001b[A\n",
      " 38%|\u001b[38;2;30;71;6m###8      \u001b[0m| 38/100 [00:02<00:06,  9.50it/s]\u001b[A\n",
      " 40%|\u001b[38;2;30;71;6m####      \u001b[0m| 40/100 [00:03<00:05, 10.36it/s]\u001b[A\n",
      " 42%|\u001b[38;2;30;71;6m####2     \u001b[0m| 42/100 [00:03<00:05, 10.45it/s]\u001b[A\n",
      " 44%|\u001b[38;2;30;71;6m####4     \u001b[0m| 44/100 [00:03<00:05, 11.06it/s]\u001b[A\n",
      " 46%|\u001b[38;2;30;71;6m####6     \u001b[0m| 46/100 [00:03<00:06,  8.79it/s]\u001b[A\n",
      " 48%|\u001b[38;2;30;71;6m####8     \u001b[0m| 48/100 [00:03<00:05,  9.92it/s]\u001b[A\n",
      " 50%|\u001b[38;2;30;71;6m#####     \u001b[0m| 50/100 [00:04<00:07,  6.80it/s]\u001b[A\n",
      " 51%|\u001b[38;2;30;71;6m#####1    \u001b[0m| 51/100 [00:04<00:07,  6.93it/s]\u001b[A\n",
      " 52%|\u001b[38;2;30;71;6m#####2    \u001b[0m| 52/100 [00:04<00:06,  7.21it/s]\u001b[A\n",
      " 53%|\u001b[38;2;30;71;6m#####3    \u001b[0m| 53/100 [00:04<00:06,  7.66it/s]\u001b[A\n",
      " 56%|\u001b[38;2;30;71;6m#####6    \u001b[0m| 56/100 [00:04<00:03, 11.21it/s]\u001b[A\n",
      " 59%|\u001b[38;2;30;71;6m#####8    \u001b[0m| 59/100 [00:05<00:02, 13.88it/s]\u001b[A\n",
      " 62%|\u001b[38;2;30;71;6m######2   \u001b[0m| 62/100 [00:05<00:02, 15.92it/s]\u001b[A\n",
      " 64%|\u001b[38;2;30;71;6m######4   \u001b[0m| 64/100 [00:05<00:02, 16.56it/s]\u001b[A\n",
      " 66%|\u001b[38;2;30;71;6m######6   \u001b[0m| 66/100 [00:05<00:01, 17.17it/s]\u001b[A\n",
      " 68%|\u001b[38;2;30;71;6m######8   \u001b[0m| 68/100 [00:05<00:01, 17.03it/s]\u001b[A\n",
      " 70%|\u001b[38;2;30;71;6m#######   \u001b[0m| 70/100 [00:05<00:01, 17.61it/s]\u001b[A\n",
      " 73%|\u001b[38;2;30;71;6m#######3  \u001b[0m| 73/100 [00:05<00:01, 18.89it/s]\u001b[A\n",
      " 75%|\u001b[38;2;30;71;6m#######5  \u001b[0m| 75/100 [00:05<00:01, 19.13it/s]\u001b[A\n",
      " 77%|\u001b[38;2;30;71;6m#######7  \u001b[0m| 77/100 [00:06<00:01, 18.11it/s]\u001b[A\n",
      " 79%|\u001b[38;2;30;71;6m#######9  \u001b[0m| 79/100 [00:06<00:01, 15.55it/s]\u001b[A\n",
      " 81%|\u001b[38;2;30;71;6m########1 \u001b[0m| 81/100 [00:06<00:01, 16.44it/s]\u001b[A\n",
      " 83%|\u001b[38;2;30;71;6m########2 \u001b[0m| 83/100 [00:06<00:01, 15.56it/s]\u001b[A\n",
      " 85%|\u001b[38;2;30;71;6m########5 \u001b[0m| 85/100 [00:06<00:00, 16.60it/s]\u001b[A\n",
      " 87%|\u001b[38;2;30;71;6m########7 \u001b[0m| 87/100 [00:06<00:00, 16.70it/s]\u001b[A\n",
      " 89%|\u001b[38;2;30;71;6m########9 \u001b[0m| 89/100 [00:06<00:00, 16.22it/s]\u001b[A\n",
      " 91%|\u001b[38;2;30;71;6m#########1\u001b[0m| 91/100 [00:06<00:00, 17.00it/s]\u001b[A\n",
      " 93%|\u001b[38;2;30;71;6m#########3\u001b[0m| 93/100 [00:07<00:00, 17.62it/s]\u001b[A\n",
      " 96%|\u001b[38;2;30;71;6m#########6\u001b[0m| 96/100 [00:07<00:00, 18.88it/s]\u001b[A\n",
      " 99%|\u001b[38;2;30;71;6m#########9\u001b[0m| 99/100 [00:07<00:00, 19.87it/s]\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m##########\u001b[0m| 100/100 [00:07<00:00, 13.61it/s]\n",
      "2023-05-16 12:01:16.068 | INFO     | src.models.train_model:trainloop:180 - Epoch 1 train 2.3051 test 2.3054 metric ['0.0966']\n",
      " 67%|\u001b[38;2;30;71;6m######6   \u001b[0m| 2/3 [00:18<00:09,  9.28s/it]\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|\u001b[38;2;30;71;6m2         \u001b[0m| 2/100 [00:00<00:05, 19.35it/s]\u001b[A\n",
      "  4%|\u001b[38;2;30;71;6m4         \u001b[0m| 4/100 [00:00<00:05, 17.99it/s]\u001b[A\n",
      "  6%|\u001b[38;2;30;71;6m6         \u001b[0m| 6/100 [00:00<00:05, 16.04it/s]\u001b[A\n",
      "  8%|\u001b[38;2;30;71;6m8         \u001b[0m| 8/100 [00:00<00:05, 15.73it/s]\u001b[A\n",
      " 10%|\u001b[38;2;30;71;6m#         \u001b[0m| 10/100 [00:00<00:05, 16.11it/s]\u001b[A\n",
      " 12%|\u001b[38;2;30;71;6m#2        \u001b[0m| 12/100 [00:00<00:05, 16.70it/s]\u001b[A\n",
      " 14%|\u001b[38;2;30;71;6m#4        \u001b[0m| 14/100 [00:00<00:05, 17.04it/s]\u001b[A\n",
      " 16%|\u001b[38;2;30;71;6m#6        \u001b[0m| 16/100 [00:00<00:04, 17.09it/s]\u001b[A\n",
      " 18%|\u001b[38;2;30;71;6m#8        \u001b[0m| 18/100 [00:01<00:04, 17.02it/s]\u001b[A\n",
      " 20%|\u001b[38;2;30;71;6m##        \u001b[0m| 20/100 [00:01<00:05, 15.59it/s]\u001b[A\n",
      " 22%|\u001b[38;2;30;71;6m##2       \u001b[0m| 22/100 [00:01<00:05, 14.03it/s]\u001b[A\n",
      " 24%|\u001b[38;2;30;71;6m##4       \u001b[0m| 24/100 [00:01<00:07, 10.79it/s]\u001b[A\n",
      " 26%|\u001b[38;2;30;71;6m##6       \u001b[0m| 26/100 [00:01<00:06, 10.87it/s]\u001b[A\n",
      " 28%|\u001b[38;2;30;71;6m##8       \u001b[0m| 28/100 [00:02<00:06, 10.39it/s]\u001b[A\n",
      " 30%|\u001b[38;2;30;71;6m###       \u001b[0m| 30/100 [00:02<00:06, 10.56it/s]\u001b[A\n",
      " 32%|\u001b[38;2;30;71;6m###2      \u001b[0m| 32/100 [00:02<00:06, 10.50it/s]\u001b[A\n",
      " 34%|\u001b[38;2;30;71;6m###4      \u001b[0m| 34/100 [00:02<00:06, 10.69it/s]\u001b[A\n",
      " 36%|\u001b[38;2;30;71;6m###6      \u001b[0m| 36/100 [00:02<00:06, 10.64it/s]\u001b[A\n",
      " 38%|\u001b[38;2;30;71;6m###8      \u001b[0m| 38/100 [00:02<00:05, 10.96it/s]\u001b[A\n",
      " 40%|\u001b[38;2;30;71;6m####      \u001b[0m| 40/100 [00:03<00:06,  8.72it/s]\u001b[A\n",
      " 41%|\u001b[38;2;30;71;6m####1     \u001b[0m| 41/100 [00:03<00:06,  8.88it/s]\u001b[A\n",
      " 43%|\u001b[38;2;30;71;6m####3     \u001b[0m| 43/100 [00:03<00:05,  9.63it/s]\u001b[A\n",
      " 45%|\u001b[38;2;30;71;6m####5     \u001b[0m| 45/100 [00:03<00:05,  9.64it/s]\u001b[A\n",
      " 47%|\u001b[38;2;30;71;6m####6     \u001b[0m| 47/100 [00:04<00:05,  9.74it/s]\u001b[A\n",
      " 49%|\u001b[38;2;30;71;6m####9     \u001b[0m| 49/100 [00:04<00:05,  9.97it/s]\u001b[A\n",
      " 51%|\u001b[38;2;30;71;6m#####1    \u001b[0m| 51/100 [00:04<00:04, 10.41it/s]\u001b[A\n",
      " 53%|\u001b[38;2;30;71;6m#####3    \u001b[0m| 53/100 [00:04<00:04, 10.32it/s]\u001b[A\n",
      " 55%|\u001b[38;2;30;71;6m#####5    \u001b[0m| 55/100 [00:04<00:03, 11.25it/s]\u001b[A\n",
      " 57%|\u001b[38;2;30;71;6m#####6    \u001b[0m| 57/100 [00:04<00:04,  9.78it/s]\u001b[A\n",
      " 59%|\u001b[38;2;30;71;6m#####8    \u001b[0m| 59/100 [00:05<00:04,  9.53it/s]\u001b[A\n",
      " 60%|\u001b[38;2;30;71;6m######    \u001b[0m| 60/100 [00:05<00:05,  7.46it/s]\u001b[A\n",
      " 61%|\u001b[38;2;30;71;6m######1   \u001b[0m| 61/100 [00:05<00:05,  7.58it/s]\u001b[A\n",
      " 63%|\u001b[38;2;30;71;6m######3   \u001b[0m| 63/100 [00:05<00:04,  9.13it/s]\u001b[A\n",
      " 65%|\u001b[38;2;30;71;6m######5   \u001b[0m| 65/100 [00:05<00:03, 10.61it/s]\u001b[A\n",
      " 67%|\u001b[38;2;30;71;6m######7   \u001b[0m| 67/100 [00:06<00:02, 11.58it/s]\u001b[A\n",
      " 69%|\u001b[38;2;30;71;6m######9   \u001b[0m| 69/100 [00:06<00:02, 12.83it/s]\u001b[A\n",
      " 71%|\u001b[38;2;30;71;6m#######1  \u001b[0m| 71/100 [00:06<00:02, 13.65it/s]\u001b[A\n",
      " 73%|\u001b[38;2;30;71;6m#######3  \u001b[0m| 73/100 [00:06<00:01, 14.09it/s]\u001b[A\n",
      " 75%|\u001b[38;2;30;71;6m#######5  \u001b[0m| 75/100 [00:06<00:01, 13.35it/s]\u001b[A\n",
      " 77%|\u001b[38;2;30;71;6m#######7  \u001b[0m| 77/100 [00:06<00:01, 12.60it/s]\u001b[A\n",
      " 79%|\u001b[38;2;30;71;6m#######9  \u001b[0m| 79/100 [00:06<00:01, 11.66it/s]\u001b[A\n",
      " 81%|\u001b[38;2;30;71;6m########1 \u001b[0m| 81/100 [00:07<00:01, 12.42it/s]\u001b[A\n",
      " 83%|\u001b[38;2;30;71;6m########2 \u001b[0m| 83/100 [00:07<00:01, 13.37it/s]\u001b[A\n",
      " 85%|\u001b[38;2;30;71;6m########5 \u001b[0m| 85/100 [00:07<00:01, 14.20it/s]\u001b[A\n",
      " 87%|\u001b[38;2;30;71;6m########7 \u001b[0m| 87/100 [00:07<00:00, 14.77it/s]\u001b[A\n",
      " 89%|\u001b[38;2;30;71;6m########9 \u001b[0m| 89/100 [00:07<00:00, 15.13it/s]\u001b[A\n",
      " 91%|\u001b[38;2;30;71;6m#########1\u001b[0m| 91/100 [00:07<00:00, 15.26it/s]\u001b[A\n",
      " 93%|\u001b[38;2;30;71;6m#########3\u001b[0m| 93/100 [00:07<00:00, 14.81it/s]\u001b[A\n",
      " 95%|\u001b[38;2;30;71;6m#########5\u001b[0m| 95/100 [00:07<00:00, 15.28it/s]\u001b[A\n",
      " 97%|\u001b[38;2;30;71;6m#########7\u001b[0m| 97/100 [00:08<00:00, 15.44it/s]\u001b[A\n",
      " 99%|\u001b[38;2;30;71;6m#########9\u001b[0m| 99/100 [00:08<00:00, 15.62it/s]\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m##########\u001b[0m| 100/100 [00:08<00:00, 12.08it/s]\n",
      "2023-05-16 12:01:27.665 | INFO     | src.models.train_model:trainloop:180 - Epoch 2 train 2.3077 test 2.3056 metric ['0.1044']\n",
      "100%|\u001b[38;2;30;71;6m##########\u001b[0m| 3/3 [00:30<00:00, 10.34s/it]\n",
      "100%|\u001b[38;2;30;71;6m##########\u001b[0m| 3/3 [00:30<00:00, 10.05s/it]\n",
      "job exception: Parent directory /Users/jeremycs/Development/machinelearning/ML22/src/models does not exist.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:30<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory /Users/jeremycs/Development/machinelearning/ML22/src/models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_result \u001b[39m=\u001b[39m fmin(\n\u001b[1;32m      2\u001b[0m     fn\u001b[39m=\u001b[39;49mobjective,\n\u001b[1;32m      3\u001b[0m     space\u001b[39m=\u001b[39;49msearch_space,\n\u001b[1;32m      4\u001b[0m     algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest,\n\u001b[1;32m      5\u001b[0m     max_evals\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     trials\u001b[39m=\u001b[39;49mTrials()\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.10/lib/python3.10/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[1;32m    541\u001b[0m         fn,\n\u001b[1;32m    542\u001b[0m         space,\n\u001b[1;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    556\u001b[0m     )\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.10/lib/python3.10/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[1;32m    672\u001b[0m     fn,\n\u001b[1;32m    673\u001b[0m     space,\n\u001b[1;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    689\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.10/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.10/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.10/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.10/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.10/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[34], line 64\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     62\u001b[0m tag \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m modelpath \u001b[39m=\u001b[39m modeldir \u001b[39m/\u001b[39m (tag \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m torch\u001b[39m.\u001b[39;49msave(model_j, modelpath)\n\u001b[1;32m     66\u001b[0m \u001b[39m# Log the saved model as an artifact in MLflow\u001b[39;00m\n\u001b[1;32m     67\u001b[0m mlflow\u001b[39m.\u001b[39mlog_artifact(local_path\u001b[39m=\u001b[39mmodelpath, artifact_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpytorch_models\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.10/lib/python3.10/site-packages/torch/serialization.py:422\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    419\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m    421\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 422\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    423\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    424\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.10/lib/python3.10/site-packages/torch/serialization.py:309\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     container \u001b[39m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/deep-learning-jHmOY0S3-py3.10/lib/python3.10/site-packages/torch/serialization.py:287\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     \u001b[39msuper\u001b[39m(_open_zipfile_writer_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileWriter(\u001b[39mstr\u001b[39;49m(name)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory /Users/jeremycs/Development/machinelearning/ML22/src/models does not exist."
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=10,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this, you can look at the best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNN_J' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_j \u001b[39m=\u001b[39m CNN_J(filters\u001b[39m=\u001b[39m\u001b[39m120\u001b[39m, units1\u001b[39m=\u001b[39m\u001b[39m66\u001b[39m, units2\u001b[39m=\u001b[39m\u001b[39m88\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m \u001b[39m# summary(model, input_size=(1, 28, 28))\u001b[39;00m\n\u001b[1;32m      3\u001b[0m trained_model, test_loss \u001b[39m=\u001b[39m  train_model\u001b[39m.\u001b[39mtrainloop(\n\u001b[1;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m      5\u001b[0m     model\u001b[39m=\u001b[39mmodel_j,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CNN_J' is not defined"
     ]
    }
   ],
   "source": [
    "model_j = CNN_J(filters=120, units1=66, units2=88, batch_size=64).to(device)\n",
    "# summary(model, input_size=(1, 28, 28))\n",
    "trained_model, test_loss =  train_model.trainloop(\n",
    "    epochs=3,\n",
    "    model=model_j,\n",
    "    train_dataloader=train_dataloader,    \n",
    "    optimizer = optim.SGD,\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(),    \n",
    "    metrics=[metrics.Accuracy()],\n",
    "    test_dataloader=test_dataloader,\n",
    "    train_steps=len(train_dataloader),\n",
    "    eval_steps=len(test_dataloader),\n",
    "    tunewriter=[\"mlflow\"],\n",
    "    learning_rate=1e-3,\n",
    "    log_dir=\"modellog\",\n",
    "    factor=0.5,\n",
    ")\n",
    "\n",
    "tag = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "modelpath = modeldir / (tag + \"model.pt\")\n",
    "torch.save(trained_model, modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "modelpath = modeldir / (tag + \"model.pt\")\n",
    "torch.save(trained_model, modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_result = {'filters': 104.0, 'units1': 58.0, 'units2': 52.0}\n",
    "# training_run_1 = {'filters': 112.0, 'units1': 72.0, 'units2': 56.0}\n",
    "# training_run_2 = {'filters': 114.0, 'units1': 72.0, 'units2': 52.0}\n",
    "# training_run_3 = {'filters': 122.0, 'units1': 66.0, 'units2': 88.0}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can also explore the UI from mlflow. It is pretty nice. The help you out, you can use the makefile by typing `make` in the terminal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-wM7qE7ca-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45c41bdaf5373703b03bba2d9bd89c97dc8ee5add9f1112e039ff04603b8e2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
