{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow for a data science project will follow these lines:\n",
    "\n",
    "1. Get and explore the data\n",
    "2. Build a model \n",
    "3. Train the model\n",
    "4. Save and predict\n",
    "\n",
    "## 1. Get and Explore the Data\n",
    "The first step can take quite some time; data quality is often something that needs to be checked, and correlations between data should often be explored and visualized.\n",
    "\n",
    "This step can be a full project on its own: you clean the data, make sure you can access it properly, and create visualizations and hypothesis to gain insight into the data that can be shown in a dashboard.\n",
    "\n",
    "The insight in the data is an essential ingredient for deciding on a model.\n",
    "\n",
    "## 2. Build a model\n",
    "Based on domain knowledge and a first exploration of the data, a model can be selected.\n",
    "\n",
    "Sometimes, the relation between features and outcome is very obvious. You might have features that\n",
    "correlate very high with the outcome variable, and a domain expert confirms that the correlations make sense.\n",
    "\n",
    "If this is the case, you can often build a simple model. If you expect to have non-linear and complex interactions between the features,\n",
    "you could use a model that works with non-linear data like a SVM plus kernel, or a random forest.\n",
    "\n",
    "If you have enough data (as a rule of thumb, a lower threshold of 1000 observations) you can consider a neural network architecture.\n",
    "If the expected complexity of the data is low, you can use a relative small network.\n",
    "If you have lots and lots of data with a high complexity, you should consider to increase the complexity of your model too.\n",
    "\n",
    "How you can build a model, and what suitable models are for different datatypes and situations, will be the subject of the whole course.\n",
    "\n",
    "## 3. Train the model\n",
    "Once you created a model, it hasnt learned anything yet. The model must be trained to learn the right connections, a bit like a baby that has to learn about what works and what doesn't.\n",
    "\n",
    "In this notebook, I will introduce you to PyTorch. Another high level library is Tensorflow, which is used a lot too.\n",
    "While the interface is comparable, the Tensorflow syntax is a bit more high-level. While this can be an advantage, \n",
    "it also has a downside: at the moment you ever need to dive a bit deeper into the architecture itself, it is much harder to\n",
    "add something new with TensorFlow, compared to PyTorch.\n",
    "\n",
    "## 4. Save and predict\n",
    "Finally, you will want to use the trained model to predict new observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "We will use the fashion MNIST dataset. You will find this dataset a lot in machine learning tutorials. It are small (28x28) images of clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src.models import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../../data/raw/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e477b34af940b6b38abae1904541b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/raw/FashionMNIST/raw/train-images-idx3-ubyte.gz to ../../data/raw/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../../data/raw/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48c54397c8e491b8c5bc380018779f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/raw/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../../data/raw/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../../data/raw/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae54bd6281b413181b9d1c4bd54b787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/raw/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/raw/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../../data/raw/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f80e8df4244a0f9dae7a0580aa1fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/raw/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/raw/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
>>>>>>> f278e88 (Edits Jeremy)
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "\n",
    "from pathlib import Path\n",
    "datadir = \"../../data/raw/\"\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=datadir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=datadir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have `torch.datasets`. They implement at minimum an `.__getitem__` and `.__len__` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data, we can use the __getitem__ method by calling an index, just like you would do with a list or array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, torch.Tensor, int)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = training_data[0]\n",
    "type(x), type(x[0]), type(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = training_data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a tuple. We can check the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the 0th item, which is the image (tensor). The other item is the label (int)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 8,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 10,
=======
     "execution_count": 8,
>>>>>>> f278e88 (Edits Jeremy)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = x[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the image has a channel-first convention: it is a 28x28 pixel image, and it has 1 channel (grey). Look into the official documentation if you want to know more about datasets and how to build your own: [docs](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "Ok, we want to batch this into a dataloader. From the documentation:\n",
    "\n",
    "> The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 9,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the length of the dataloader different from the dataset? We had 60000 items before..."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 10,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938, 157)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 14,
=======
     "execution_count": 10,
>>>>>>> f278e88 (Edits Jeremy)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 11,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
<<<<<<< HEAD
     "execution_count": 15,
=======
     "execution_count": 11,
>>>>>>> f278e88 (Edits Jeremy)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(train_dataloader))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what do we see here? Our datashape has four dimensions:\n",
    "\n",
    "- 64: this is the batch size. Every batch has 64 observations; in this case 64 images\n",
    "- 1: this is the channel. Colorimages typically have 3 channels. Our images have just one color, and thus 1 channel. So images can have more channels (e.g. infrared etc)\n",
    "- (28,28) : this is the actual image, with dimensions 28x28\n",
    "\n",
    "Lets visualize the first example, the first image:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 12,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 18,
=======
     "execution_count": 12,
>>>>>>> f278e88 (Edits Jeremy)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = X[1]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 13,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<matplotlib.image.AxesImage at 0x13876b0d0>"
      ]
     },
     "execution_count": 19,
=======
       "<matplotlib.image.AxesImage at 0x7f1f2473fbe0>"
      ]
     },
     "execution_count": 13,
>>>>>>> f278e88 (Edits Jeremy)
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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",
=======
      "image/png": "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",
>>>>>>> f278e88 (Edits Jeremy)
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 14,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 512]         401,920\n",
      "              ReLU-3                  [-1, 512]               0\n",
      "            Linear-4                  [-1, 256]         131,328\n",
      "              ReLU-5                  [-1, 256]               0\n",
      "            Linear-6                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 2.04\n",
      "Estimated Total Size (MB): 2.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you recognize the setup from the `linearmodel` notebook. \n",
    "\n",
    "- We will `Flatten` the image. That means we will transform our (64, 1, 28, 28) data into (64, 784) shaped data. What we do here, is flattening the image into a one dimensional vector.\n",
    "- We have a stack of hidden layers. These are essentially dotproducts. Our vector of 784 (28*28) elements is transformed into 512 elements, and then into 10 elements because we have 10 classes.\n",
    "- in between the linear transformations you can see the activation functions,here a `ReLu` \n",
    "- The `forward` method is what is called during training. This gives you control over the flow of information: it is easy to create some parallel flow of data if you want to do something like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an optimizer. We will dive into this in later lessons.\n",
    "\n",
    "For now, it is enough to know this:\n",
    "\n",
    "Your model makes a prediction. But how does the model know if it is right, or wrong?\n",
    "And, more specific: how does the model know which weights it needs to modify in order"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 15,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn the weights"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 16,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938, 60000)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 30,
=======
     "execution_count": 16,
>>>>>>> f278e88 (Edits Jeremy)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 17,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"../../models/test\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": 18,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": 19,
>>>>>>> f278e88 (Edits Jeremy)
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2023-04-25 21:01:54.845 | INFO     | src.data.data_tools:dir_add_timestamp:129 - Logging to ../../models/test/20230425-2101\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 938/938 [00:13<00:00, 68.79it/s]\n",
      "2023-04-25 21:02:08.850 | INFO     | src.models.train_model:trainloop:180 - Epoch 0 train 0.4950 test 0.4195 metric ['0.8503']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 938/938 [00:14<00:00, 64.97it/s]\n",
      "2023-04-25 21:02:23.708 | INFO     | src.models.train_model:trainloop:180 - Epoch 1 train 0.3545 test 0.4423 metric ['0.8366']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 938/938 [00:16<00:00, 56.81it/s]\n",
      "2023-04-25 21:02:40.704 | INFO     | src.models.train_model:trainloop:180 - Epoch 2 train 0.3135 test 0.3699 metric ['0.8750']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 938/938 [00:17<00:00, 54.15it/s]\n",
      "2023-04-25 21:02:58.502 | INFO     | src.models.train_model:trainloop:180 - Epoch 3 train 0.2973 test 0.3227 metric ['0.8900']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 938/938 [00:18<00:00, 50.24it/s]\n",
      "2023-04-25 21:03:17.682 | INFO     | src.models.train_model:trainloop:180 - Epoch 4 train 0.2816 test 0.3478 metric ['0.8756']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:22<00:00, 16.57s/it]\n"
=======
      "2023-04-30 20:03:02.184 | INFO     | src.data.data_tools:dir_add_timestamp:129 - Logging to ../../models/test/20230430-2003\n",
      "2023-04-30 20:03:02.460323: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 20:03:05.119143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [00:01<00:00, 46.99it/s]\n",
      "2023-04-30 20:03:09.134 | INFO     | src.models.train_model:trainloop:180 - Epoch 0 train 1.0499 test 0.7224 metric ['0.7175']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [00:02<00:00, 23.02it/s]\n",
      "2023-04-30 20:03:12.251 | INFO     | src.models.train_model:trainloop:180 - Epoch 1 train 0.6291 test 0.6778 metric ['0.7575']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [00:01<00:00, 25.74it/s]\n",
      "2023-04-30 20:03:14.664 | INFO     | src.models.train_model:trainloop:180 - Epoch 2 train 0.6019 test 0.5504 metric ['0.8041']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [00:00<00:00, 56.78it/s]\n",
      "2023-04-30 20:03:16.036 | INFO     | src.models.train_model:trainloop:180 - Epoch 3 train 0.5237 test 0.5791 metric ['0.7841']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [00:00<00:00, 59.97it/s]\n",
      "2023-04-30 20:03:17.385 | INFO     | src.models.train_model:trainloop:180 - Epoch 4 train 0.4884 test 0.5227 metric ['0.8147']\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:09<00:00,  1.96s/it]\n"
>>>>>>> f278e88 (Edits Jeremy)
     ]
    }
   ],
   "source": [
    "model, test_loss = train_model.trainloop(\n",
    "    epochs=5,\n",
    "    model=model,\n",
    "    optimizer=optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=[accuracy],\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=len(train_dataloader),\n",
    "    eval_steps=50,\n",
    "    tunewriter=[\"tensorboard\", \"gin\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = Path(\"../../models\") \n",
    "model_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = model_dir / \"trained_model\"\n",
    "torch.save(model, modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a batch $X$, $y$ and make a prediction $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(test_dataloader))\n",
    "yhat = loaded_model(X)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy:\n",
    "- for every example we have 10 numbers\n",
    "- the location with the highest value is the prediction\n",
    "- we can get the index with `argmax` over dimension 1\n",
    "- we compare that index with the original number\n",
    "- This gives us a count of all the correct predictions\n",
    "- dividing that through the total length gives us the accuracy percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.6875"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (yhat.argmax(dim=1) == y).sum() / len(y)\n",
    "acc.item() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is the accuracy for a single batch! \n",
    "Get another batch by running next() in the cell above, and calculate the accuracy again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 20:03:18.006 | INFO     | src.data.data_tools:clean_dir:96 - Clean out ../../models/test\n"
     ]
    }
   ],
   "source": [
    "cleanup = True\n",
    "from src.data import data_tools\n",
    "# to remove the trained model\n",
    "if cleanup:\n",
    "    modelpath.unlink()\n",
    "    data_tools.clean_dir(log_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-wM7qE7ca-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.8.13"
=======
   "version": "3.10.11"
>>>>>>> f278e88 (Edits Jeremy)
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45c41bdaf5373703b03bba2d9bd89c97dc8ee5add9f1112e039ff04603b8e2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
